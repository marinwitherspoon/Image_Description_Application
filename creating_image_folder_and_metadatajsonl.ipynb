{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U \"huggingface_hub[cli]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing required libraries \n",
    "!pip install -q git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the required libraries \n",
    "import json \n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Dataset for finetuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if below dataset structure is required. Use the code snippet below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_structure(source_folder, dest_folder, split_percent):\n",
    "    \"\"\"\n",
    "    input: Takes the images folder where all our captions images are kept\n",
    "    source_folder : folder where all the images are located\n",
    "    dest_folder : where our output repository should be stored\n",
    "    split_percent: amount of split required for training-testing\n",
    "    output: Appropriately makes the file structure according to huggingface \n",
    "            my_dataset_repository\n",
    "                            ├── folder/train/image1.png\n",
    "                            ├── folder/train/image2.png\n",
    "                            ├── folder/train/image3.png\n",
    "                            ├── folder/test/image4.png\n",
    "                            ├── folder/test/metadata.jsonl\n",
    "                            └── folder/train/metadata.jsonl\n",
    "    \"\"\"\n",
    "    ## creating testing and training folders in the destination folder\n",
    "    train_folder = os.path.join(dest_folder, 'train')\n",
    "    test_folder = os.path.join(dest_folder, 'test')\n",
    "\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok = True)\n",
    "\n",
    "    # getting the list of images in source folder \n",
    "    image_files = [f for f in os.listdir(source_folder) if f.endswith(('.jpg', '.jpeg','.png', '.gif'))]\n",
    "\n",
    "    # Calculate the number of images for train and test based on split \n",
    "    num_train = int(len(image_files)* 0.80)\n",
    "    num_test =  int(len(image_files) * (1 - split_percent))\n",
    "\n",
    "    # randomly shuffling images\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # copying images to train folder \n",
    "    for image_file in image_files[:num_train]:\n",
    "        source_path = os.path.join(source_folder, image_file)\n",
    "        dest_path = os.path.join(train_folder, image_file)\n",
    "        shutil.copy(source_path, dest_path)\n",
    "\n",
    "    # copying images to test folder\n",
    "    for image_file in image_files[num_train:]:\n",
    "        source_path = os.path.join(source_folder, image_file)\n",
    "        dest_path = os.path.join(test_folder, image_file)\n",
    "        shutil.copy(source_path, dest_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = r\"C:\\Users\\smeet\\Desktop\\data science capstone\\images_and_captions\\Images\"\n",
    "dest_folder = r\"C:\\Users\\smeet\\Desktop\\data science capstone\\images_and_captions\\Image_Split\"\n",
    "split_percent = 0.80\n",
    "create_dataset_structure(source_folder, dest_folder, split_percent )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7195"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### checking if there are images lost while doing preprocessing\n",
    "len(os.listdir(source_folder))\n",
    "\n",
    "x = os.path.join(dest_folder, 'test')\n",
    "y =os.path.join(dest_folder, 'train')\n",
    "len(os.listdir(x)) + len(os.listdir(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hugging_face_model_format(source_folder, dest_folder):\n",
    "    \"\"\" \n",
    "    input: Takes the processed captions file \n",
    "    source_folder: This is where our processed captions will be stored\n",
    "    dest_folder: This is where our images (train/test) are saved. \n",
    "\n",
    "    output: Creates a output JSON File that is required by for the huggingface input model \n",
    "           eg :  [{ \"file_name\" : \"image.name\" , \"text\" : \"description of the text\"} , ...\n",
    "    \"\"\"\n",
    "    \n",
    "    ## getting the processed captions \n",
    "    with open(source_folder , 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    ## this model requires a  list of captions where each image is in {} format shown above in docstring\n",
    "    random_captions = []\n",
    "    for k , (image,caption) in data.items():\n",
    "        random_captions.append({\"file_name\" : str(image) , \"text\": str(caption)})\n",
    "    \n",
    "    df = pd.DataFrame(random_captions)\n",
    "    df_unique = df.sample(frac=1).drop_duplicates(subset='file_name').reset_index(drop=True)\n",
    "\n",
    "    random_captions = df_unique.to_dict(orient='records')\n",
    "    \n",
    "    with open(os.path.join(dest_folder, 'metadata.jsonl'), 'w') as f:\n",
    "        for item in random_captions:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "    return random_captions\n",
    "\n",
    "\n",
    "source_folder  = r\"C:\\Users\\smeet\\Desktop\\data science capstone\\data_structure\\data_captions_processed.json\"\n",
    "dest_folder = r\"C:\\Users\\smeet\\Desktop\\data science capstone\\images_and_captions\\Image_Split\"\n",
    "captions = hugging_face_model_format(source_folder, dest_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "physically moved the metadata.jsonl files into the folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40455"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(source_folder, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "len(data)\n",
    "len(captions)*5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
