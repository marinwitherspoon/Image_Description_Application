{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U \"huggingface_hub[cli]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing required libraries \n",
    "!pip install -q git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the required libraries \n",
    "import json \n",
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Dataset for finetuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if below dataset structure is required. Use the code snippet below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_structure(source_folder, dest_folder, split_percent):\n",
    "    \"\"\"\n",
    "    Create File Structure for the Dataset (huggingface)\n",
    "\n",
    "    Parameters:\n",
    "        - source_folder (str): Path to folder containing images.\n",
    "        - dest_folder (str): Path to the destination folder for the dataset structure.\n",
    "        - split_percent (str): Percentage of images to be used for training.\n",
    "\n",
    "    output: Appropriately makes the file structure according to huggingface \n",
    "            my_dataset_repository\n",
    "                            ├── folder/train/image1.png\n",
    "                            ├── folder/train/image2.png\n",
    "                            ├── folder/train/image3.png\n",
    "                            ├── folder/test/image4.png\n",
    "                            ├── folder/test/metadata.jsonl\n",
    "                            └── folder/train/metadata.jsonl\n",
    "    \"\"\"\n",
    "    ## creating testing and training folders in the destination folder\n",
    "    train_folder = os.path.join(dest_folder, 'train')\n",
    "    test_folder = os.path.join(dest_folder, 'test')\n",
    "\n",
    "    os.makedirs(train_folder, exist_ok=True)\n",
    "    os.makedirs(test_folder, exist_ok = True)\n",
    "\n",
    "    # getting the list of images in source folder \n",
    "    image_files = [f for f in os.listdir(source_folder) if f.endswith(('.jpg', '.jpeg','.png', '.gif'))]\n",
    "\n",
    "    # Calculate the number of images for train and test based on split \n",
    "    num_train = int(len(image_files)* split_percent)\n",
    "    num_test =  int(len(image_files) * (1 - split_percent))\n",
    "\n",
    "    # randomly shuffling images\n",
    "    random.shuffle(image_files)\n",
    "\n",
    "    # copying images to train folder \n",
    "    for image_file in image_files[:num_train]:\n",
    "        source_path = os.path.join(source_folder, image_file)\n",
    "        dest_path = os.path.join(train_folder, image_file)\n",
    "        shutil.copy(source_path, dest_path)\n",
    "\n",
    "    # copying images to test folder\n",
    "    for image_file in image_files[num_train:]:\n",
    "        source_path = os.path.join(source_folder, image_file)\n",
    "        dest_path = os.path.join(test_folder, image_file)\n",
    "        shutil.copy(source_path, dest_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = r\"C:\\Users\\smeet\\Desktop\\data science capstone\\images_and_captions\\Images\"\n",
    "dest_folder = r\"C:\\Users\\smeet\\Desktop\\data science capstone\\images_and_captions\\Image_Split\"\n",
    "split_percent = 0.80\n",
    "create_dataset_structure(source_folder, dest_folder, split_percent )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7195"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### checking if there are images lost while doing preprocessing\n",
    "print(\"Number of images in source folder: \", len(os.listdir(source_folder)))\n",
    "print(\"Number of images in destination train folder: \", len(os.path.join(dest_folder, 'train')))\n",
    "print(\"Number of images in destination test folder: \", len(os.path.join(dest_folder, 'test')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hugging_face_model_format(source_folder, dest_folder):\n",
    "    \"\"\" \n",
    "    input (str) : Path to captions (processed) json file\n",
    "    source_folder: This is where our processed captions will be stored\n",
    "    dest_folder: This is where our images (train/test) are saved. \n",
    "\n",
    "    output: Creates a output JSON File that is required by for the huggingface input model \n",
    "           eg :  [{ \"file_name\" : \"image.name\" , \"text\" : \"description of the text\"} , ...\n",
    "    \"\"\"\n",
    "    \n",
    "    ## getting the processed captions \n",
    "    with open(source_folder , 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    ## this model requires a  list of captions where each image is in {} format shown above in docstring\n",
    "    random_captions = []\n",
    "    for k , (image,caption) in data.items():\n",
    "        random_captions.append({\"file_name\" : str(image) , \"text\": str(caption)})\n",
    "    \n",
    "    ## Each image has 5 captions each --> so we randomly drop the duplicate captions \n",
    "    df = pd.DataFrame(random_captions)\n",
    "    df_unique = df.sample(frac=1).drop_duplicates(subset='file_name').reset_index(drop=True)\n",
    "\n",
    "    random_captions = df_unique.to_dict(orient='records')\n",
    "    \n",
    "    # The images folder need a metadata.jsonl file to associate images with captions. [specific hugginface model requirement]\n",
    "    with open(os.path.join(dest_folder, 'metadata.jsonl'), 'w') as f:\n",
    "        for item in random_captions:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "    return random_captions\n",
    "\n",
    "# \n",
    "source_folder  = r\"C:\\Users\\smeet\\Desktop\\data science capstone\\data_structure\\data_captions_processed.json\"\n",
    "dest_folder = r\"C:\\Users\\smeet\\Desktop\\data science capstone\\images_and_captions\\Image_Split\"\n",
    "captions = hugging_face_model_format(source_folder, dest_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "physically moved the metadata.jsonl files into the folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40455"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if still our output has same number of captions.\n",
    "with open(source_folder, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "len(data)\n",
    "len(captions)*5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
